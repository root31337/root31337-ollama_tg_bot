import logging
import subprocess
import asyncio
import signal
import os
from typing import Dict, Any, List, Optional, Tuple
import json
import time
from datetime import datetime
from functools import wraps
import re
import statistics
from dataclasses import dataclass
from enum import Enum

from telegram import Update, InlineKeyboardButton, InlineKeyboardMarkup
from telegram.ext import (
    ApplicationBuilder,
    CommandHandler,
    MessageHandler,
    filters,
    CallbackQueryHandler,
    ContextTypes
)
import ollama
from ollama import ResponseError

# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
from config import CONFIG

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
def setup_logging():
    logging.basicConfig(
        level=CONFIG['LOG_LEVEL'],
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        handlers=[
            logging.FileHandler('bot.log', encoding='utf-8'),
            logging.StreamHandler()
        ]
    )
    logging.getLogger('httpx').setLevel(logging.WARNING)

logger = logging.getLogger(__name__)

# –ì–ª–æ–±–∞–ª—å–Ω–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ
user_data: Dict[int, Dict] = {}
context_memory: Dict[int, Dict] = {}
rate_limit_counters: Dict[int, Tuple[int, float]] = {}
model_info_cache: Dict[str, Dict] = {}
active_requests: Dict[int, asyncio.Task] = {}
shutdown_event = asyncio.Event()
benchmark_results: Dict[str, List[Dict]] = {}

# –ö–ª–∞—Å—Å—ã –¥–ª—è –±–µ–Ω—á–º–∞—Ä–∫–∞
class BenchmarkTask:
    def __init__(self, id: str, name: str, prompt: str, expected_answer: str):
        self.id = id
        self.name = name
        self.prompt = prompt
        self.expected_answer = expected_answer.lower()
    
    def evaluate(self, response: str) -> Tuple[float, str]:
        """–û—Ü–µ–Ω–∏–≤–∞–µ—Ç –æ—Ç–≤–µ—Ç –º–æ–¥–µ–ª–∏ –æ—Ç 0 –¥–æ 1"""
        response_lower = response.lower()
        
        # –ü—Ä–æ—Å—Ç–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –Ω–∞–ª–∏—á–∏–µ –æ–∂–∏–¥–∞–µ–º–æ–≥–æ –æ—Ç–≤–µ—Ç–∞
        if self.expected_answer in response_lower:
            return 1.0, "‚úÖ –ü–æ–ª–Ω—ã–π –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç"
        
        # –î–ª—è –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏—Ö –∑–∞–¥–∞—á –ø—ã—Ç–∞–µ–º—Å—è –∏–∑–≤–ª–µ—á—å —á–∏—Å–ª–æ
        if self.id == 'math_problem':
            numbers = re.findall(r'\d+', response)
            if numbers:
                try:
                    last_number = int(numbers[-1])
                    if last_number == 6:
                        return 1.0, "‚úÖ –ü—Ä–∞–≤–∏–ª—å–Ω—ã–π —á–∏—Å–ª–æ–≤–æ–π –æ—Ç–≤–µ—Ç"
                    else:
                        return 0.5, f"‚ö†Ô∏è –ß–∏—Å–ª–æ –Ω–∞–π–¥–µ–Ω–æ, –Ω–æ –Ω–µ–≤–µ—Ä–Ω–æ–µ: {last_number}"
                except:
                    pass
        
        # –î–ª—è –ª–æ–≥–∏—á–µ—Å–∫–∏—Ö –∑–∞–¥–∞—á
        if self.id == 'logic_puzzle':
            if '–æ–¥–∏–Ω–∞–∫–æ–≤' in response_lower or '—Ä–∞–≤–Ω' in response_lower or 'same' in response_lower:
                return 1.0, "‚úÖ –ü—Ä–∞–≤–∏–ª—å–Ω—ã–π –ª–æ–≥–∏—á–µ—Å–∫–∏–π –≤—ã–≤–æ–¥"
        
        # –î–ª—è –ø–µ—Ä–µ–≤–æ–¥–∞
        if self.id == 'translation':
            if 'red car' in response_lower or 'the red car' in response_lower:
                return 1.0, "‚úÖ –ü—Ä–∞–≤–∏–ª—å–Ω—ã–π –ø–µ—Ä–µ–≤–æ–¥"
            elif 'red' in response_lower and 'car' in response_lower:
                return 0.8, "‚úÖ –û—Å–Ω–æ–≤–Ω—ã–µ —Å–ª–æ–≤–∞ –ø–µ—Ä–µ–≤–µ–¥–µ–Ω—ã –ø—Ä–∞–≤–∏–ª—å–Ω–æ"
        
        # –î–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∫–æ–¥–∞
        if self.id == 'code_generation':
            if 'def factorial' in response_lower:
                return 1.0, "‚úÖ –ü—Ä–∞–≤–∏–ª—å–Ω–æ–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ñ—É–Ω–∫—Ü–∏–∏"
            elif 'factorial' in response_lower and ('def ' in response_lower or 'function' in response_lower):
                return 0.7, "‚ö†Ô∏è –§—É–Ω–∫—Ü–∏—è –Ω–∞–π–¥–µ–Ω–∞, –Ω–æ –º–æ–≥—É—Ç –±—ã—Ç—å –æ—à–∏–±–∫–∏"
        
        # –î–ª—è —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏
        if self.id == 'summarization':
            keywords = ['–¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫', '–ª–µ—á–µ–Ω–∏', '–∞–Ω–∞–ª–∏–∑', '–ø—Ä–æ–≥–Ω–æ–∑', '—Ä–æ–±–æ—Ç', '—Ö–∏—Ä—É—Ä–≥']
            found_keywords = sum(1 for kw in keywords if kw in response_lower)
            if found_keywords >= 2:
                return 0.8, "‚úÖ –û—Å–Ω–æ–≤–Ω—ã–µ –ø—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞ —É–ø–æ–º—è–Ω—É—Ç—ã"
        
        return 0.0, "‚ùå –û—Ç–≤–µ—Ç –Ω–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç –æ–∂–∏–¥–∞–µ–º–æ–º—É"

@dataclass
class BenchmarkResult:
    model: str
    task_id: str
    task_name: str
    score: float
    response_time: float
    tokens_generated: int
    tokens_per_second: float
    evaluation: str
    raw_response: str
    timestamp: float
    
    def to_dict(self):
        return {
            'model': self.model,
            'task_id': self.task_id,
            'task_name': self.task_name,
            'score': self.score,
            'response_time': self.response_time,
            'tokens_generated': self.tokens_generated,
            'tokens_per_second': self.tokens_per_second,
            'evaluation': self.evaluation,
            'timestamp': self.timestamp
        }

class BenchmarkStatus(Enum):
    NOT_STARTED = "not_started"
    RUNNING = "running"
    COMPLETED = "completed"
    FAILED = "failed"

# –î–µ–∫–æ—Ä–∞—Ç–æ—Ä—ã
def rate_limit_check(func):
    @wraps(func)
    async def wrapper(update: Update, context: ContextTypes.DEFAULT_TYPE):
        user_id = update.effective_user.id
        if check_rate_limit(user_id):
            await update.message.reply_text("‚ö†Ô∏è –í—ã –ø—Ä–µ–≤—ã—Å–∏–ª–∏ –ª–∏–º–∏—Ç —Å–æ–æ–±—â–µ–Ω–∏–π. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø–æ–¥–æ–∂–¥–∏—Ç–µ –º–∏–Ω—É—Ç—É.")
            return
        return await func(update, context)
    return wrapper

def handle_errors(func):
    @wraps(func)
    async def wrapper(*args, **kwargs):
        try:
            return await func(*args, **kwargs)
        except asyncio.CancelledError:
            raise
        except Exception as e:
            logger.error(f"Error in {func.__name__}: {str(e)}", exc_info=True)
            
            update = None
            for arg in args:
                if isinstance(arg, Update):
                    update = arg
                    break
            
            if update:
                try:
                    if hasattr(update, 'callback_query') and update.callback_query:
                        await update.callback_query.message.reply_text("‚ö†Ô∏è –û—à–∏–±–∫–∞, –ø–æ–ø—Ä–æ–±—É–π—Ç–µ —Å–Ω–æ–≤–∞")
                    elif hasattr(update, 'message') and update.message:
                        await update.message.reply_text("‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∑–∞–ø—Ä–æ—Å–∞")
                except Exception as send_error:
                    logger.error(f"–û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ —Å–æ–æ–±—â–µ–Ω–∏—è: {send_error}")
    return wrapper

def cancel_previous_request(func):
    @wraps(func)
    async def wrapper(update: Update, context: ContextTypes.DEFAULT_TYPE):
        user_id = update.effective_user.id
        if user_id in active_requests:
            active_requests[user_id].cancel()
            try:
                await active_requests[user_id]
            except asyncio.CancelledError:
                pass
        task = asyncio.create_task(func(update, context))
        active_requests[user_id] = task
        try:
            return await task
        finally:
            active_requests.pop(user_id, None)
    return wrapper

# –£—Ç–∏–ª–∏—Ç—ã
def setup_directories():
    """–°–æ–∑–¥–∞–µ—Ç –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏"""
    os.makedirs('backups', exist_ok=True)
    os.makedirs('logs', exist_ok=True)
    os.makedirs('temp', exist_ok=True)
    os.makedirs('benchmarks', exist_ok=True)

async def backup_data():
    """–ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–µ —Å–æ–∑–¥–∞–Ω–∏–µ —Ä–µ–∑–µ—Ä–≤–Ω—ã—Ö –∫–æ–ø–∏–π"""
    try:
        timestamp = int(time.time())
        async with asyncio.Lock():
            with open(f'backups/user_data_{timestamp}.json', 'w', encoding='utf-8') as f:
                json.dump(user_data, f, ensure_ascii=False, indent=2)
            with open(f'backups/context_memory_{timestamp}.json', 'w', encoding='utf-8') as f:
                json.dump(context_memory, f, ensure_ascii=False, indent=2)
            
            # –û—á–∏—Å—Ç–∫–∞ —Å—Ç–∞—Ä—ã—Ö –±—ç–∫–∞–ø–æ–≤
            backup_files = sorted([f for f in os.listdir('backups') if f.startswith('user_data_')])
            for old_file in backup_files[:-5]:
                os.remove(f'backups/{old_file}')
            
            logger.info("–†–µ–∑–µ—Ä–≤–Ω–æ–µ –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –∑–∞–≤–µ—Ä—à–µ–Ω–æ")
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ —Ä–µ–∑–µ—Ä–≤–Ω–æ–≥–æ –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏—è: {e}")

async def backup_task(context: ContextTypes.DEFAULT_TYPE):
    """–ü–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–æ–µ —Ä–µ–∑–µ—Ä–≤–Ω–æ–µ –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏–µ"""
    if shutdown_event.is_set():
        return
    
    await backup_data()

async def load_backup():
    """–ó–∞–≥—Ä—É–∑–∫–∞ –ø–æ—Å–ª–µ–¥–Ω–µ–π —Ä–µ–∑–µ—Ä–≤–Ω–æ–π –∫–æ–ø–∏–∏"""
    try:
        backup_files = sorted([f for f in os.listdir('backups') if f.startswith('user_data_')])
        if backup_files:
            with open(f'backups/{backup_files[-1]}', 'r', encoding='utf-8') as f:
                global user_data
                user_data = json.load(f)
        
        backup_files = sorted([f for f in os.listdir('backups') if f.startswith('context_memory_')])
        if backup_files:
            with open(f'backups/{backup_files[-1]}', 'r', encoding='utf-8') as f:
                global context_memory
                context_memory = json.load(f)
        
        logger.info("–†–µ–∑–µ—Ä–≤–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã")
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Ä–µ–∑–µ—Ä–≤–Ω–æ–π –∫–æ–ø–∏–∏: {e}")

def check_rate_limit(user_id: int) -> bool:
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è —Å–∫–æ—Ä–æ—Å—Ç–∏ –∑–∞–ø—Ä–æ—Å–æ–≤"""
    current_time = time.time()
    count, last_time = rate_limit_counters.get(user_id, (0, current_time))
    
    if current_time - last_time > 60:
        rate_limit_counters[user_id] = (1, current_time)
        return False
    
    if count >= CONFIG['RATE_LIMIT']:
        return True
    
    rate_limit_counters[user_id] = (count + 1, last_time)
    return False

async def get_available_models(refresh: bool = False) -> List[str]:
    """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π —Å –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ–º"""
    if not refresh and model_info_cache:
        return sorted(
            list(model_info_cache.keys()),
            key=lambda x: CONFIG['MODEL_PRIORITY'].get(x.split(':')[0], 10)
        )
    
    try:
        result = await asyncio.to_thread(
            subprocess.run,
            ['ollama', 'list'],
            capture_output=True,
            text=True,
            check=True,
            timeout=10
        )
        models = [line.split()[0] for line in result.stdout.strip().split('\n')[1:]]
        
        # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∫—ç—à–∞
        for model in models:
            if model not in model_info_cache:
                model_info_cache[model] = {
                    'name': model, 
                    'last_used': None,
                    'usage_count': 0,
                    'benchmark_score': 0.0,
                    'benchmark_tested': False
                }
        
        return sorted(
            models,
            key=lambda x: CONFIG['MODEL_PRIORITY'].get(x.split(':')[0], 10)
        )
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å–ø–∏—Å–∫–∞ –º–æ–¥–µ–ª–µ–π: {e}")
        return []

async def get_model_info(model: str) -> bool:
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ –º–æ–¥–µ–ª–∏"""
    try:
        await asyncio.to_thread(ollama.show, model=model)
        return True
    except Exception:
        return False

def split_long_message(text: str, max_length: int = None) -> List[str]:
    """–†–∞–∑–±–∏–≤–∫–∞ –¥–ª–∏–Ω–Ω–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è –Ω–∞ —á–∞—Å—Ç–∏"""
    max_length = max_length or CONFIG['MAX_MESSAGE_LENGTH']
    parts = []
    while text:
        if len(text) <= max_length:
            parts.append(text)
            break
        
        # –ü—ã—Ç–∞–µ–º—Å—è —Ä–∞–∑–±–∏—Ç—å –ø–æ –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω—ã–º —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—è–º
        for delimiter in ['\n\n', '\n', '. ', '! ', '? ', ' ', '']:
            split_pos = text.rfind(delimiter, 0, max_length)
            if split_pos > 0:
                parts.append(text[:split_pos + len(delimiter)])
                text = text[split_pos + len(delimiter):]
                break
        else:
            # –ï—Å–ª–∏ —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª–µ–π –Ω–µ—Ç, —Ä–∞–∑–±–∏–≤–∞–µ–º –ø–æ max_length
            parts.append(text[:max_length])
            text = text[max_length:]
    
    return parts

def trim_context(context: List[Dict], max_length: int = None) -> List[Dict]:
    """–û–±—Ä–µ–∑–∫–∞ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –¥–æ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π –¥–ª–∏–Ω—ã"""
    max_length = max_length or CONFIG['MAX_CONTEXT_LENGTH']
    total_length = sum(len(msg['content']) for msg in context)
    
    while total_length > max_length and len(context) > 1:
        removed = context.pop(0)
        total_length -= len(removed['content'])
    
    return context

def initialize_user(user_id: int):
    """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""
    if user_id not in user_data:
        user_data[user_id] = {
            'current_model': CONFIG['DEFAULT_MODEL'],
            'preferences': {
                'save_context': True,
                'markdown_formatting': True,
                'notifications': True,
                'typing_indicator': True,
                'stream_responses': False
            },
            'stats': {
                'messages_sent': 0,
                'models_used': {},
                'last_active': time.time(),
                'total_tokens': 0,
                'total_requests': 0,
                'benchmarks_run': 0
            },
            'is_admin': user_id in CONFIG['ADMIN_IDS'],
            'created_at': time.time(),
            'benchmark_status': BenchmarkStatus.NOT_STARTED.value,
            'current_benchmark': None
        }
    
    if user_id not in context_memory:
        context_memory[user_id] = {}
    
    current_model = user_data[user_id]['current_model']
    if current_model not in context_memory[user_id]:
        context_memory[user_id][current_model] = []

async def send_long_message(update: Update, text: str, parse_mode: str = None):
    """–û—Ç–ø—Ä–∞–≤–∫–∞ –¥–ª–∏–Ω–Ω—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π —Å —Ä–∞–∑–±–∏–≤–∫–æ–π"""
    parts = split_long_message(text)
    for i, part in enumerate(parts):
        if i == 0:
            await update.message.reply_text(part, parse_mode=parse_mode)
        else:
            await update.effective_chat.send_message(part, parse_mode=parse_mode)

# –§—É–Ω–∫—Ü–∏–∏ –±–µ–Ω—á–º–∞—Ä–∫–∞
async def run_benchmark_task(model: str, task: BenchmarkTask) -> Optional[BenchmarkResult]:
    """–ó–∞–ø—É—Å–∫ –æ–¥–Ω–æ–≥–æ —Ç–µ—Å—Ç–æ–≤–æ–≥–æ –∑–∞–¥–∞–Ω–∏—è –¥–ª—è –º–æ–¥–µ–ª–∏"""
    try:
        start_time = time.time()
        
        response = await asyncio.wait_for(
            asyncio.to_thread(
                ollama.chat,
                model=model,
                messages=[{'role': 'user', 'content': task.prompt}],
                options={
                    **CONFIG['MODEL_OPTIONS'],
                    'temperature': CONFIG['BENCHMARK_TEMPERATURE'],
                    'num_predict': CONFIG['BENCHMARK_MAX_TOKENS']
                }
            ),
            timeout=CONFIG['BENCHMARK_TIMEOUT']
        )
        
        end_time = time.time()
        response_time = end_time - start_time
        answer = response['message']['content']
        
        # –ü–æ–ª—É—á–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É —Ç–æ–∫–µ–Ω–æ–≤
        eval_count = response.get('eval_count', 0)
        tokens_per_second = eval_count / response_time if response_time > 0 else 0
        
        # –û—Ü–µ–Ω–∏–≤–∞–µ–º –æ—Ç–≤–µ—Ç
        score, evaluation = task.evaluate(answer)
        
        result = BenchmarkResult(
            model=model,
            task_id=task.id,
            task_name=task.name,
            score=score,
            response_time=response_time,
            tokens_generated=eval_count,
            tokens_per_second=tokens_per_second,
            evaluation=evaluation,
            raw_response=answer[:200] + "..." if len(answer) > 200 else answer,
            timestamp=time.time()
        )
        
        logger.info(f"–ë–µ–Ω—á–º–∞—Ä–∫: {model} - {task.name} - –û—Ü–µ–Ω–∫–∞: {score:.2f} - –í—Ä–µ–º—è: {response_time:.2f}—Å")
        
        return result
        
    except asyncio.TimeoutError:
        logger.warning(f"–¢–∞–π–º–∞—É—Ç –±–µ–Ω—á–º–∞—Ä–∫–∞ –¥–ª—è –º–æ–¥–µ–ª–∏ {model} –Ω–∞ –∑–∞–¥–∞—á–µ {task.name}")
        return None
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –±–µ–Ω—á–º–∞—Ä–∫–∞ –¥–ª—è –º–æ–¥–µ–ª–∏ {model}: {e}")
        return None

async def run_full_benchmark(models: List[str], user_id: int):
    """–ó–∞–ø—É—Å–∫ –ø–æ–ª–Ω–æ–≥–æ –±–µ–Ω—á–º–∞—Ä–∫–∞ –¥–ª—è —Å–ø–∏—Å–∫–∞ –º–æ–¥–µ–ª–µ–π"""
    user_data[user_id]['benchmark_status'] = BenchmarkStatus.RUNNING.value
    
    tasks = [BenchmarkTask(**task) for task in CONFIG['BENCHMARK_TASKS']]
    results = {}
    
    total_tasks = len(models) * len(tasks)
    completed_tasks = 0
    
    for model in models:
        model_results = []
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–∏
        if not await get_model_info(model):
            logger.warning(f"–ú–æ–¥–µ–ª—å {model} –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞ –¥–ª—è –±–µ–Ω—á–º–∞—Ä–∫–∞")
            continue
        
        for task in tasks:
            if shutdown_event.is_set():
                break
            
            result = await run_benchmark_task(model, task)
            if result:
                model_results.append(result)
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
                if model not in benchmark_results:
                    benchmark_results[model] = []
                benchmark_results[model].append(result.to_dict())
            
            completed_tasks += 1
            progress = (completed_tasks / total_tasks) * 100
            
            # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç—É—Å
            user_data[user_id]['current_benchmark'] = {
                'progress': progress,
                'current_model': model,
                'current_task': task.name,
                'completed_tasks': completed_tasks,
                'total_tasks': total_tasks
            }
        
        if model_results:
            avg_score = statistics.mean([r.score for r in model_results])
            avg_time = statistics.mean([r.response_time for r in model_results])
            avg_tps = statistics.mean([r.tokens_per_second for r in model_results])
            
            results[model] = {
                'avg_score': avg_score,
                'avg_time': avg_time,
                'avg_tps': avg_tps,
                'results': model_results
            }
            
            # –û–±–Ω–æ–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –º–æ–¥–µ–ª–∏
            if model in model_info_cache:
                model_info_cache[model]['benchmark_score'] = avg_score
                model_info_cache[model]['benchmark_tested'] = True
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ —Ñ–∞–π–ª
    if results:
        await save_benchmark_results(results, user_id)
    
    user_data[user_id]['benchmark_status'] = BenchmarkStatus.COMPLETED.value
    user_data[user_id]['stats']['benchmarks_run'] += 1
    
    return results

async def save_benchmark_results(results: Dict, user_id: int):
    """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –±–µ–Ω—á–º–∞—Ä–∫–∞ –≤ —Ñ–∞–π–ª"""
    try:
        timestamp = int(time.time())
        filename = f'benchmarks/benchmark_{user_id}_{timestamp}.json'
        
        data = {
            'timestamp': timestamp,
            'user_id': user_id,
            'results': {},
            'summary': {}
        }
        
        for model, model_data in results.items():
            data['results'][model] = {
                'avg_score': model_data['avg_score'],
                'avg_time': model_data['avg_time'],
                'avg_tps': model_data['avg_tps'],
                'task_results': [r.to_dict() for r in model_data['results']]
            }
        
        # –°–æ–∑–¥–∞–µ–º —Å–≤–æ–¥–∫—É
        sorted_models = sorted(results.items(), key=lambda x: x[1]['avg_score'], reverse=True)
        data['summary'] = {
            'top_model': sorted_models[0][0] if sorted_models else None,
            'ranking': [{'model': m, 'score': d['avg_score']} for m, d in sorted_models],
            'total_models': len(results),
            'timestamp': timestamp
        }
        
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        
        logger.info(f"–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –±–µ–Ω—á–º–∞—Ä–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {filename}")
        return filename
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –±–µ–Ω—á–º–∞—Ä–∫–∞: {e}")
        return None

def format_benchmark_results(results: Dict) -> str:
    """–§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –±–µ–Ω—á–º–∞—Ä–∫–∞ –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è"""
    if not results:
        return "‚ùå –ù–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è"
    
    lines = ["üìä *–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –±–µ–Ω—á–º–∞—Ä–∫–∞ –º–æ–¥–µ–ª–µ–π*\n"]
    
    sorted_models = sorted(results.items(), key=lambda x: x[1]['avg_score'], reverse=True)
    
    for i, (model, data) in enumerate(sorted_models):
        score_stars = "‚≠ê" * int(data['avg_score'] * 5)
        lines.append(f"\n*{i+1}. {model}*")
        lines.append(f"   –û—Ü–µ–Ω–∫–∞: {data['avg_score']:.2f}/1.0 {score_stars}")
        lines.append(f"   –°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è: {data['avg_time']:.2f}—Å")
        lines.append(f"   –¢–æ–∫–µ–Ω–æ–≤/—Å–µ–∫: {data['avg_tps']:.1f}")
        
        # –î–µ—Ç–∞–ª–∏ –ø–æ –∑–∞–¥–∞—á–∞–º
        lines.append(f"   *–î–µ—Ç–∞–ª–∏:*")
        for task_result in data['results']:
            status = "‚úÖ" if task_result.score >= 0.7 else "‚ö†Ô∏è" if task_result.score >= 0.3 else "‚ùå"
            lines.append(f"   {status} {task_result.task_name}: {task_result.score:.1f} ({task_result.response_time:.1f}—Å)")
    
    # –°–≤–æ–¥–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞
    lines.append("\n*üìà –°–≤–æ–¥–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞:*")
    lines.append("```")
    lines.append(f"{'–ú–æ–¥–µ–ª—å':<20} {'–û—Ü–µ–Ω–∫–∞':<8} {'–í—Ä–µ–º—è':<8} {'T/s':<8}")
    lines.append("-" * 50)
    for model, data in sorted_models:
        lines.append(f"{model:<20} {data['avg_score']:.2f}     {data['avg_time']:.2f}—Å    {data['avg_tps']:.1f}")
    lines.append("```")
    
    return "\n".join(lines)

async def get_model_leaderboard() -> str:
    """–ü–æ–ª—É—á–µ–Ω–∏–µ —Ç–∞–±–ª–∏—Ü—ã –ª–∏–¥–µ—Ä–æ–≤ –º–æ–¥–µ–ª–µ–π"""
    tested_models = {m: d for m, d in model_info_cache.items() if d.get('benchmark_tested', False)}
    
    if not tested_models:
        return "üìä *–¢–∞–±–ª–∏—Ü–∞ –ª–∏–¥–µ—Ä–æ–≤*\n\n–ü–æ–∫–∞ –Ω–µ—Ç –ø—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π. –ó–∞–ø—É—Å—Ç–∏—Ç–µ –±–µ–Ω—á–º–∞—Ä–∫!"
    
    sorted_models = sorted(
        tested_models.items(),
        key=lambda x: x[1].get('benchmark_score', 0),
        reverse=True
    )
    
    lines = ["üèÜ *–¢–∞–±–ª–∏—Ü–∞ –ª–∏–¥–µ—Ä–æ–≤ –º–æ–¥–µ–ª–µ–π*\n"]
    lines.append("```")
    lines.append(f"{'–ú–µ—Å—Ç–æ':<6} {'–ú–æ–¥–µ–ª—å':<25} {'–û—Ü–µ–Ω–∫–∞':<8} {'–¢–µ—Å—Ç–æ–≤':<8} {'–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–π':<12}")
    lines.append("-" * 65)
    
    for i, (model, data) in enumerate(sorted_models[:10]):
        score = data.get('benchmark_score', 0)
        tests = len([r for r in benchmark_results.get(model, []) if r.get('model') == model])
        uses = data.get('usage_count', 0)
        
        medal = ""
        if i == 0:
            medal = "ü•á "
        elif i == 1:
            medal = "ü•à "
        elif i == 2:
            medal = "ü•â "
        
        lines.append(f"{medal}{i+1:<3} {model:<25} {score:.2f}      {tests:<8} {uses:<12}")
    
    lines.append("```")
    
    if len(sorted_models) > 10:
        lines.append(f"\n... –∏ –µ—â–µ {len(sorted_models) - 10} –º–æ–¥–µ–ª–µ–π")
    
    return "\n".join(lines)

# –û–±—Ä–∞–±–æ—Ç—á–∏–∫–∏ –∫–æ–º–∞–Ω–¥
@handle_errors
async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –∫–æ–º–∞–Ω–¥—ã /start"""
    user_id = update.effective_user.id
    initialize_user(user_id)
    
    status = "‚úÖ –í–∫–ª" if user_data[user_id]['preferences']['save_context'] else "‚ùå –í—ã–∫–ª"
    stream_status = "‚úÖ –í–∫–ª" if user_data[user_id]['preferences']['stream_responses'] else "‚ùå –í—ã–∫–ª"
    
    keyboard = [
        [InlineKeyboardButton("üìù –í—ã–±—Ä–∞—Ç—å –º–æ–¥–µ–ª—å", callback_data='show_models')],
        [InlineKeyboardButton("üÜï –ù–æ–≤—ã–π –¥–∏–∞–ª–æ–≥", callback_data='new_chat')],
        [InlineKeyboardButton(f"üß† –ö–æ–Ω—Ç–µ–∫—Å—Ç: {status}", callback_data='toggle_context')],
        [InlineKeyboardButton(f"üåÄ –ü–æ—Ç–æ–∫: {stream_status}", callback_data='toggle_stream')],
        [InlineKeyboardButton("‚öôÔ∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∏", callback_data='settings')],
        [InlineKeyboardButton("üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞", callback_data='show_stats')]
    ]
    
    if user_data[user_id]['is_admin']:
        keyboard.append([InlineKeyboardButton("üõ† –ê–¥–º–∏–Ω-–ø–∞–Ω–µ–ª—å", callback_data='admin_panel')])
        keyboard.append([InlineKeyboardButton("üèÜ –ë–µ–Ω—á–º–∞—Ä–∫", callback_data='benchmark_menu')])
    
    await update.message.reply_text(
        "ü§ñ *–î–æ–±—Ä–æ –ø–æ–∂–∞–ª–æ–≤–∞—Ç—å –≤ Ollama Telegram Bot!*\n\n"
        "–Ø –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è—é –¥–æ—Å—Ç—É–ø –∫ —Ä–∞–∑–ª–∏—á–Ω—ã–º —è–∑—ã–∫–æ–≤—ã–º –º–æ–¥–µ–ª—è–º —á–µ—Ä–µ–∑ Ollama.",
        reply_markup=InlineKeyboardMarkup(keyboard),
        parse_mode='Markdown'
    )

@handle_errors
@rate_limit_check
async def benchmark_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–ö–æ–º–∞–Ω–¥–∞ –¥–ª—è –∑–∞–ø—É—Å–∫–∞ –±–µ–Ω—á–º–∞—Ä–∫–∞"""
    user_id = update.effective_user.id
    initialize_user(user_id)
    
    if not user_data[user_id]['is_admin']:
        await update.message.reply_text("üö´ –≠—Ç–∞ –∫–æ–º–∞–Ω–¥–∞ –¥–æ—Å—Ç—É–ø–Ω–∞ —Ç–æ–ª—å–∫–æ –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä–∞–º")
        return
    
    await show_benchmark_menu(update.callback_query)

@handle_errors
async def leaderboard_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–ö–æ–º–∞–Ω–¥–∞ –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è —Ç–∞–±–ª–∏—Ü—ã –ª–∏–¥–µ—Ä–æ–≤"""
    user_id = update.effective_user.id
    initialize_user(user_id)
    
    leaderboard = await get_model_leaderboard()
    await update.message.reply_text(leaderboard, parse_mode='Markdown')

@handle_errors
@rate_limit_check
@cancel_previous_request
async def handle_message(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π"""
    user_id = update.effective_user.id
    initialize_user(user_id)
    current_model = user_data[user_id]['current_model']
    message_text = update.message.text
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ –º–æ–¥–µ–ª–∏
    if CONFIG['MODEL_HEALTH_CHECK'] and not await get_model_info(current_model):
        await update.message.reply_text(f"‚ö†Ô∏è –ú–æ–¥–µ–ª—å {current_model} –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –¥—Ä—É–≥—É—é –º–æ–¥–µ–ª—å.")
        return
    
    # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
    user_data[user_id]['stats']['messages_sent'] += 1
    user_data[user_id]['stats']['last_active'] = time.time()
    user_data[user_id]['stats']['total_requests'] += 1
    
    if current_model not in user_data[user_id]['stats']['models_used']:
        user_data[user_id]['stats']['models_used'][current_model] = 0
    user_data[user_id]['stats']['models_used'][current_model] += 1
    
    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
    if user_data[user_id]['preferences']['save_context']:
        if current_model not in context_memory[user_id]:
            context_memory[user_id][current_model] = []
        
        context_memory[user_id][current_model].append({'role': 'user', 'content': message_text})
        context_memory[user_id][current_model] = trim_context(context_memory[user_id][current_model])
    
    # –ò–Ω–¥–∏–∫–∞—Ç–æ—Ä –Ω–∞–±–æ—Ä–∞
    if user_data[user_id]['preferences']['typing_indicator']:
        await asyncio.sleep(CONFIG['TYPING_DELAY'])
        await context.bot.send_chat_action(chat_id=update.effective_chat.id, action='typing')
    
    # –£–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –æ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
    notification = None
    if user_data[user_id]['preferences']['notifications']:
        notification = await update.message.reply_text("üîÑ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞...")
    
    try:
        messages = context_memory[user_id][current_model] if user_data[user_id]['preferences']['save_context'] else []
        messages.append({'role': 'user', 'content': message_text})
        
        # –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—Ç–≤–µ—Ç–∞
        if user_data[user_id]['preferences']['markdown_formatting']:
            header = (
                f"*–ú–æ–¥–µ–ª—å:* {current_model}\n"
                f"*–ó–∞–ø—Ä–æ—Å:* `{message_text[:100]}{'...' if len(message_text) > 100 else ''}`\n\n"
                f"*–û—Ç–≤–µ—Ç:*\n"
            )
            parse_mode = 'Markdown'
        else:
            header = (
                f"–ú–æ–¥–µ–ª—å: {current_model}\n"
                f"–ó–∞–ø—Ä–æ—Å: {message_text[:100]}{'...' if len(message_text) > 100 else ''}\n\n"
                f"–û—Ç–≤–µ—Ç:\n"
            )
            parse_mode = None
        
        if user_data[user_id]['preferences']['stream_responses']:
            # –ü–æ—Ç–æ–∫–æ–≤–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è
            full_response = ""
            message = await update.message.reply_text(header + "‚åõ –ù–∞—á–∏–Ω–∞—é –≥–µ–Ω–µ—Ä–∞—Ü–∏—é...", parse_mode=parse_mode)
            
            async def stream_response():
                nonlocal full_response
                response = await asyncio.to_thread(
                    ollama.chat,
                    model=current_model,
                    messages=messages,
                    options=CONFIG['MODEL_OPTIONS'],
                    stream=True
                )
                
                for chunk in response:
                    if shutdown_event.is_set():
                        raise asyncio.CancelledError()
                    
                    content = chunk['message']['content']
                    full_response += content
                    
                    # –û–±–Ω–æ–≤–ª—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ –∫–∞–∂–¥—ã–µ 50 —Å–∏–º–≤–æ–ª–æ–≤
                    if len(full_response) % 50 == 0:
                        try:
                            await message.edit_text(header + full_response, parse_mode=parse_mode)
                        except:
                            pass
                
                return full_response
            
            try:
                answer = await asyncio.wait_for(
                    stream_response(),
                    timeout=CONFIG['MODEL_TIMEOUT']
                )
                await message.edit_text(header + answer, parse_mode=parse_mode)
                
                # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ —Ç–æ–∫–µ–Ω–æ–≤
                if 'eval_count' in response:
                    user_data[user_id]['stats']['total_tokens'] += response['eval_count']
                
                # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ—Ç–≤–µ—Ç–∞ –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç
                if user_data[user_id]['preferences']['save_context']:
                    context_memory[user_id][current_model].append({'role': 'assistant', 'content': answer})
                
            except asyncio.TimeoutError:
                await message.edit_text(header + full_response + "\n\n‚ö†Ô∏è –î–æ—Å—Ç–∏–≥–Ω—É—Ç —Ç–∞–π–º–∞—É—Ç –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏", parse_mode=parse_mode)
                raise
                
        else:
            # –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è
            response = await asyncio.wait_for(
                asyncio.to_thread(
                    ollama.chat,
                    model=current_model,
                    messages=messages,
                    options=CONFIG['MODEL_OPTIONS']
                ),
                timeout=CONFIG['MODEL_TIMEOUT']
            )
            
            answer = response['message']['content']
            
            # –†–∞–∑–±–∏–≤–∫–∞ –∏ –æ—Ç–ø—Ä–∞–≤–∫–∞ —Å–æ–æ–±—â–µ–Ω–∏—è
            message_parts = split_long_message(answer, CONFIG['MAX_MESSAGE_LENGTH'] - len(header))
            
            # –ü–µ—Ä–≤–∞—è —á–∞—Å—Ç—å —Å –∑–∞–≥–æ–ª–æ–≤–∫–æ–º
            first_part = header + message_parts[0]
            if notification:
                try:
                    await notification.edit_text(first_part, parse_mode=parse_mode)
                except Exception as e:
                    logger.warning(f"–û—à–∏–±–∫–∞ —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏—è —Å–æ–æ–±—â–µ–Ω–∏—è: {e}")
                    await update.message.reply_text(first_part, parse_mode=parse_mode)
            else:
                await update.message.reply_text(first_part, parse_mode=parse_mode)
            
            # –û—Å—Ç–∞–ª—å–Ω—ã–µ —á–∞—Å—Ç–∏
            for part in message_parts[1:]:
                await update.effective_chat.send_message(part, parse_mode=parse_mode)
            
            # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ —Ç–æ–∫–µ–Ω–æ–≤
            if 'eval_count' in response:
                user_data[user_id]['stats']['total_tokens'] += response['eval_count']
            
            # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ—Ç–≤–µ—Ç–∞ –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç
            if user_data[user_id]['preferences']['save_context']:
                context_memory[user_id][current_model].append({'role': 'assistant', 'content': answer})
        
        # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –º–æ–¥–µ–ª–∏
        model_info_cache[current_model]['last_used'] = time.time()
        model_info_cache[current_model]['usage_count'] = model_info_cache[current_model].get('usage_count', 0) + 1
    
    except asyncio.TimeoutError:
        error_msg = (
            "‚è≥ –ú–æ–¥–µ–ª—å –¥–æ–ª–≥–æ –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –æ—Ç–≤–µ—Ç. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ:\n"
            "1. –°–æ–∫—Ä–∞—Ç–∏—Ç—å –∑–∞–ø—Ä–æ—Å\n"
            "2. –û—Ç–ø—Ä–∞–≤–∏—Ç—å –µ–≥–æ —Å–Ω–æ–≤–∞\n"
            "3. –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –±–æ–ª–µ–µ –ª–µ–≥–∫—É—é –º–æ–¥–µ–ª—å (/model)\n"
            "4. –û—Ç–∫–ª—é—á–∏—Ç—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ (/settings)"
        )
        logger.warning(f"–¢–∞–π–º–∞—É—Ç –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è {user_id} —Å –º–æ–¥–µ–ª—å—é {current_model}")
        if notification:
            await notification.edit_text(error_msg)
        else:
            await update.message.reply_text(error_msg)
    
    except ResponseError as e:
        if "Message too long" in str(e):
            error_msg = "‚ö†Ô∏è –û—Ç–≤–µ—Ç –º–æ–¥–µ–ª–∏ —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã–π. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –±–æ–ª–µ–µ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π –∑–∞–ø—Ä–æ—Å."
        else:
            error_msg = f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –º–æ–¥–µ–ª–∏: {str(e)}"
        
        logger.error(f"–û—à–∏–±–∫–∞ –º–æ–¥–µ–ª–∏ –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è {user_id}: {error_msg}")
        if notification:
            await notification.edit_text(error_msg)
        else:
            await update.message.reply_text(error_msg)
    
    except Exception as e:
        error_msg = "‚ö†Ô∏è –ü—Ä–æ–∏–∑–æ—à–ª–∞ –Ω–µ–ø—Ä–µ–¥–≤–∏–¥–µ–Ω–Ω–∞—è –æ—à–∏–±–∫–∞"
        logger.error(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è {user_id}: {e}", exc_info=True)
        if notification:
            await notification.edit_text(error_msg)
        else:
            await update.message.reply_text(error_msg)

@handle_errors
async def button_handler(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ inline-–∫–Ω–æ–ø–æ–∫"""
    query = update.callback_query
    user_id = query.from_user.id
    
    try:
        await query.answer()
    except Exception as e:
        if "Query is too old" in str(e):
            logger.warning(f"–ü—Ä–æ—Å—Ä–æ—á–µ–Ω–Ω—ã–π callback: {query.data}")
            return
        raise
    
    initialize_user(user_id)
    
    # –û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–Ω–æ–ø–æ–∫ –±–µ–Ω—á–º–∞—Ä–∫–∞
    if query.data == 'benchmark_menu':
        await show_benchmark_menu(query)
    
    elif query.data == 'run_full_benchmark':
        await run_full_benchmark_handler(update, context)
    
    elif query.data == 'show_leaderboard':
        await show_leaderboard_handler(update, context)
    
    elif query.data == 'show_benchmark_tasks':
        await show_benchmark_tasks_handler(update, context)
    
    elif query.data == 'test_single_model':
        await test_single_model_handler(update, context)
    
    elif query.data.startswith('benchmark_model_'):
        await benchmark_model_handler(update, context)
    
    # ... –æ—Å—Ç–∞–ª—å–Ω—ã–µ –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–∏ –∫–Ω–æ–ø–æ–∫ –∏–∑ –ø—Ä–µ–¥—ã–¥—É—â–µ–π –≤–µ—Ä—Å–∏–∏
    elif query.data == 'toggle_context':
        user_data[user_id]['preferences']['save_context'] = not user_data[user_id]['preferences']['save_context']
        status = "‚úÖ –í–∫–ª" if user_data[user_id]['preferences']['save_context'] else "‚ùå –í—ã–∫–ª"
        await show_main_menu(query, f"üß† –ö–æ–Ω—Ç–µ–∫—Å—Ç: {status}")
    
    elif query.data == 'toggle_stream':
        user_data[user_id]['preferences']['stream_responses'] = not user_data[user_id]['preferences']['stream_responses']
        status = "‚úÖ –í–∫–ª" if user_data[user_id]['preferences']['stream_responses'] else "‚ùå –í—ã–∫–ª"
        await show_main_menu(query, f"üåÄ –ü–æ—Ç–æ–∫–æ–≤–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è: {status}")
    
    elif query.data == 'show_models':
        await show_models_menu(query)
    
    elif query.data == 'refresh_models':
        await query.edit_message_text("üîÑ –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ –º–æ–¥–µ–ª–µ–π...")
        await show_models_menu(query, refresh=True)
    
    elif query.data == 'new_chat':
        context_memory[user_id] = {}
        await show_main_menu(query, "üÜï –ù–æ–≤—ã–π –¥–∏–∞–ª–æ–≥ –Ω–∞—á–∞—Ç. –ö–æ–Ω—Ç–µ–∫—Å—Ç –æ—á–∏—â–µ–Ω.")
    
    elif query.data.startswith('model_'):
        model_name = query.data[6:]
        if CONFIG['MODEL_HEALTH_CHECK'] and not await get_model_info(model_name):
            await query.answer(f"‚ö†Ô∏è –ú–æ–¥–µ–ª—å {model_name} –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞", show_alert=True)
            return
        
        user_data[user_id]['current_model'] = model_name
        model_info_cache[model_name]['last_used'] = time.time()
        model_info_cache[model_name]['usage_count'] = model_info_cache[model_name].get('usage_count', 0) + 1
        await show_main_menu(query, f"‚úÖ –í—ã–±—Ä–∞–Ω–∞ –º–æ–¥–µ–ª—å: {model_name}")
    
    elif query.data == 'settings':
        await show_settings_menu(query)
    
    elif query.data == 'toggle_markdown':
        user_data[user_id]['preferences']['markdown_formatting'] = not user_data[user_id]['preferences']['markdown_formatting']
        await show_settings_menu(query)
    
    elif query.data == 'toggle_notifications':
        user_data[user_id]['preferences']['notifications'] = not user_data[user_id]['preferences']['notifications']
        await show_settings_menu(query)
    
    elif query.data == 'toggle_typing':
        user_data[user_id]['preferences']['typing_indicator'] = not user_data[user_id]['preferences']['typing_indicator']
        await show_settings_menu(query)
    
    elif query.data == 'show_stats':
        await show_stats_menu(query)
    
    elif query.data == 'admin_panel':
        if user_data[user_id]['is_admin']:
            await show_admin_panel(query)
        else:
            await query.answer("üö´ –£ –≤–∞—Å –Ω–µ—Ç –ø—Ä–∞–≤ –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä–∞", show_alert=True)
    
    elif query.data == 'back_to_menu':
        await show_main_menu(query)
    
    elif query.data == 'force_backup':
        if user_data[user_id]['is_admin']:
            await query.answer("üîÑ –°–æ–∑–¥–∞–Ω–∏–µ –±—ç–∫–∞–ø–∞...", show_alert=False)
            await backup_data()
            await query.answer("‚úÖ –ë—ç–∫–∞–ø —Å–æ–∑–¥–∞–Ω", show_alert=False)
        else:
            await query.answer("üö´ –£ –≤–∞—Å –Ω–µ—Ç –ø—Ä–∞–≤ –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä–∞", show_alert=True)

@handle_errors
async def show_main_menu(query, text: str = None):
    """–û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≥–ª–∞–≤–Ω–æ–≥–æ –º–µ–Ω—é"""
    user_id = query.from_user.id
    status = "‚úÖ –í–∫–ª" if user_data[user_id]['preferences']['save_context'] else "‚ùå –í—ã–∫–ª"
    stream_status = "‚úÖ –í–∫–ª" if user_data[user_id]['preferences']['stream_responses'] else "‚ùå –í—ã–∫–ª"
    
    keyboard = [
        [InlineKeyboardButton("üìù –í—ã–±—Ä–∞—Ç—å –º–æ–¥–µ–ª—å", callback_data='show_models')],
        [InlineKeyboardButton("üÜï –ù–æ–≤—ã–π –¥–∏–∞–ª–æ–≥", callback_data='new_chat')],
        [InlineKeyboardButton(f"üß† –ö–æ–Ω—Ç–µ–∫—Å—Ç: {status}", callback_data='toggle_context')],
        [InlineKeyboardButton(f"üåÄ –ü–æ—Ç–æ–∫: {stream_status}", callback_data='toggle_stream')],
        [InlineKeyboardButton("‚öôÔ∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∏", callback_data='settings')],
        [InlineKeyboardButton("üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞", callback_data='show_stats')]
    ]
    
    if user_data[user_id]['is_admin']:
        keyboard.append([InlineKeyboardButton("üõ† –ê–¥–º–∏–Ω-–ø–∞–Ω–µ–ª—å", callback_data='admin_panel')])
        keyboard.append([InlineKeyboardButton("üèÜ –ë–µ–Ω—á–º–∞—Ä–∫", callback_data='benchmark_menu')])
    
    try:
        await query.edit_message_text(
            text=text or "–ì–ª–∞–≤–Ω–æ–µ –º–µ–Ω—é",
            reply_markup=InlineKeyboardMarkup(keyboard),
            parse_mode='Markdown'
        )
    except Exception as e:
        logger.warning(f"–û—à–∏–±–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –º–µ–Ω—é: {e}")

@handle_errors
async def show_models_menu(query, refresh: bool = False):
    """–û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ –º–µ–Ω—é –≤—ã–±–æ—Ä–∞ –º–æ–¥–µ–ª–µ–π"""
    user_id = query.from_user.id
    models = await get_available_models(refresh=refresh)
    
    if not models:
        await query.edit_message_text(
            "‚ùå –ù–µ—Ç –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π. –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ Ollama –∑–∞–ø—É—â–µ–Ω.",
            reply_markup=InlineKeyboardMarkup([
                [InlineKeyboardButton("üîÑ –û–±–Ω–æ–≤–∏—Ç—å", callback_data='refresh_models')],
                [InlineKeyboardButton("üîô –ù–∞–∑–∞–¥", callback_data='back_to_menu')]
            ])
        )
        return
    
    buttons = []
    for model in models:
        model_info = model_info_cache.get(model, {})
        last_used = model_info.get('last_used')
        usage_count = model_info.get('usage_count', 0)
        
        if last_used:
            last_used_str = datetime.fromtimestamp(last_used).strftime('%d.%m')
            label = f"{model} ({last_used_str}, {usage_count}x)"
        else:
            label = f"{model} (–Ω–æ–≤—ã–π)"
        
        buttons.append(InlineKeyboardButton(label, callback_data=f"model_{model}"))
    
    keyboard = [buttons[i:i + 2] for i in range(0, len(buttons), 2)]
    keyboard.append([InlineKeyboardButton("üîÑ –û–±–Ω–æ–≤–∏—Ç—å —Å–ø–∏—Å–æ–∫", callback_data='refresh_models')])
    keyboard.append([InlineKeyboardButton("üîô –ù–∞–∑–∞–¥", callback_data='back_to_menu')])
    
    await query.edit_message_text(
        "–í—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª—å (–¥–∞—Ç–∞ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è, –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–π):",
        reply_markup=InlineKeyboardMarkup(keyboard)
    )

@handle_errors
async def show_settings_menu(query):
    """–û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ –º–µ–Ω—é –Ω–∞—Å—Ç—Ä–æ–µ–∫"""
    user_id = query.from_user.id
    prefs = user_data[user_id]['preferences']
    
    settings_text = (
        "‚öôÔ∏è *–ù–∞—Å—Ç—Ä–æ–π–∫–∏*\n\n"
        f"‚Ä¢ üß† –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞: {'‚úÖ –í–∫–ª' if prefs['save_context'] else '‚ùå –í—ã–∫–ª'}\n"
        f"‚Ä¢ üìù Markdown —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ: {'‚úÖ –í–∫–ª' if prefs['markdown_formatting'] else '‚ùå –í—ã–∫–ª'}\n"
        f"‚Ä¢ üîî –£–≤–µ–¥–æ–º–ª–µ–Ω–∏—è: {'‚úÖ –í–∫–ª' if prefs['notifications'] else '‚ùå –í—ã–∫–ª'}\n"
        f"‚Ä¢ ‚úçÔ∏è –ò–Ω–¥–∏–∫–∞—Ç–æ—Ä –Ω–∞–±–æ—Ä–∞: {'‚úÖ –í–∫–ª' if prefs['typing_indicator'] else '‚ùå –í—ã–∫–ª'}\n"
        f"‚Ä¢ üåÄ –ü–æ—Ç–æ–∫–æ–≤–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è: {'‚úÖ –í–∫–ª' if prefs['stream_responses'] else '‚ùå –í—ã–∫–ª'}"
    )
    
    keyboard = [
        [InlineKeyboardButton("–ü–µ—Ä–µ–∫–ª—é—á–∏—Ç—å –∫–æ–Ω—Ç–µ–∫—Å—Ç", callback_data='toggle_context')],
        [InlineKeyboardButton("–ü–µ—Ä–µ–∫–ª—é—á–∏—Ç—å Markdown", callback_data='toggle_markdown')],
        [InlineKeyboardButton("–ü–µ—Ä–µ–∫–ª—é—á–∏—Ç—å —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è", callback_data='toggle_notifications')],
        [InlineKeyboardButton("–ü–µ—Ä–µ–∫–ª—é—á–∏—Ç—å –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä", callback_data='toggle_typing')],
        [InlineKeyboardButton("–ü–µ—Ä–µ–∫–ª—é—á–∏—Ç—å –ø–æ—Ç–æ–∫", callback_data='toggle_stream')],
        [InlineKeyboardButton("üîô –ù–∞–∑–∞–¥", callback_data='back_to_menu')]
    ]
    
    await query.edit_message_text(
        settings_text,
        reply_markup=InlineKeyboardMarkup(keyboard),
        parse_mode='Markdown'
    )

@handle_errors
async def show_stats_menu(query):
    """–û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏"""
    user_id = query.from_user.id
    stats = user_data[user_id]['stats']
    
    models_used = "\n".join(
        f"‚Ä¢ {model}: {count} —Å–æ–æ–±—â." 
        for model, count in sorted(
            stats['models_used'].items(),
            key=lambda x: x[1],
            reverse=True
        )[:5]
    )
    
    stats_text = (
        f"üìä *–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞*\n\n"
        f"‚Ä¢ –í—Å–µ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏–π: {stats['messages_sent']}\n"
        f"‚Ä¢ –í—Å–µ–≥–æ –∑–∞–ø—Ä–æ—Å–æ–≤: {stats['total_requests']}\n"
        f"‚Ä¢ –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏:\n{models_used}\n"
        f"‚Ä¢ –í—Å–µ–≥–æ —Ç–æ–∫–µ–Ω–æ–≤: {stats.get('total_tokens', 0)}\n"
        f"‚Ä¢ –ü–æ—Å–ª–µ–¥–Ω—è—è –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å: {datetime.fromtimestamp(stats['last_active']).strftime('%d.%m %H:%M')}\n"
        f"‚Ä¢ –¢–µ–∫—É—â–∞—è –º–æ–¥–µ–ª—å: {user_data[user_id]['current_model']}\n"
        f"‚Ä¢ –ê–∫—Ç–∏–≤–µ–Ω —Å: {datetime.fromtimestamp(user_data[user_id]['created_at']).strftime('%d.%m.%Y')}"
    )
    
    await query.edit_message_text(
        stats_text,
        reply_markup=InlineKeyboardMarkup([
            [InlineKeyboardButton("üîô –ù–∞–∑–∞–¥", callback_data='back_to_menu')]
        ]),
        parse_mode='Markdown'
    )

@handle_errors
async def show_admin_panel(query):
    """–ê–¥–º–∏–Ω-–ø–∞–Ω–µ–ª—å"""
    user_id = query.from_user.id
    if not user_data[user_id]['is_admin']:
        await query.answer("üö´ –£ –≤–∞—Å –Ω–µ—Ç –ø—Ä–∞–≤ –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä–∞", show_alert=True)
        return
    
    total_users = len(user_data)
    active_users = sum(1 for uid, data in user_data.items() 
                      if time.time() - data['stats']['last_active'] < 86400)
    total_tokens = sum(u['stats'].get('total_tokens', 0) for u in user_data.values())
    total_models = len(model_info_cache)
    
    # –¢–æ–ø –º–æ–¥–µ–ª–µ–π –∏–∑ –±–µ–Ω—á–º–∞—Ä–∫–∞
    tested_models = {m: d for m, d in model_info_cache.items() if d.get('benchmark_tested', False)}
    top_benchmark_models = sorted(
        tested_models.items(),
        key=lambda x: x[1].get('benchmark_score', 0),
        reverse=True
    )[:3]
    
    benchmark_info = ""
    if top_benchmark_models:
        benchmark_info = "\n*üèÜ –¢–æ–ø –º–æ–¥–µ–ª–µ–π –ø–æ –±–µ–Ω—á–º–∞—Ä–∫—É:*\n"
        for model, info in top_benchmark_models:
            score = info.get('benchmark_score', 0)
            benchmark_info += f"‚Ä¢ {model}: {score:.2f}/1.0\n"
    
    admin_text = (
        "üõ† *–ê–¥–º–∏–Ω-–ø–∞–Ω–µ–ª—å*\n\n"
        f"‚Ä¢ –í—Å–µ–≥–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π: {total_users}\n"
        f"‚Ä¢ –ê–∫—Ç–∏–≤–Ω—ã—Ö –∑–∞ —Å—É—Ç–∫–∏: {active_users}\n"
        f"‚Ä¢ –ó–∞–≥—Ä—É–∂–µ–Ω–æ –º–æ–¥–µ–ª–µ–π: {total_models}\n"
        f"‚Ä¢ –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ —Ç–æ–∫–µ–Ω–æ–≤: {total_tokens}\n"
        f"‚Ä¢ –ü—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–æ –º–æ–¥–µ–ª–µ–π: {len(tested_models)}\n"
        f"{benchmark_info}"
    )
    
    keyboard = [
        [InlineKeyboardButton("üèÜ –ë–µ–Ω—á–º–∞—Ä–∫ –º–æ–¥–µ–ª–µ–π", callback_data='benchmark_menu')],
        [InlineKeyboardButton("üîÑ –û–±–Ω–æ–≤–∏—Ç—å –¥–∞–Ω–Ω—ã–µ", callback_data='admin_panel')],
        [InlineKeyboardButton("üíæ –°–æ–∑–¥–∞—Ç—å –±—ç–∫–∞–ø", callback_data='force_backup')],
        [InlineKeyboardButton("üîô –ù–∞–∑–∞–¥", callback_data='back_to_menu')]
    ]
    
    await query.edit_message_text(
        admin_text,
        reply_markup=InlineKeyboardMarkup(keyboard),
        parse_mode='Markdown'
    )

# –ù–æ–≤—ã–µ –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–∏ –¥–ª—è –±–µ–Ω—á–º–∞—Ä–∫–∞
@handle_errors
async def benchmark_menu_handler(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –º–µ–Ω—é –±–µ–Ω—á–º–∞—Ä–∫–∞"""
    query = update.callback_query
    user_id = query.from_user.id
    
    await query.answer()
    initialize_user(user_id)
    
    await show_benchmark_menu(query)

async def show_benchmark_menu(query, text: str = None):
    """–û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ –º–µ–Ω—é –±–µ–Ω—á–º–∞—Ä–∫–∞"""
    user_id = query.from_user.id
    
    keyboard = [
        [InlineKeyboardButton("üöÄ –ó–∞–ø—É—Å—Ç–∏—Ç—å –ø–æ–ª–Ω—ã–π –±–µ–Ω—á–º–∞—Ä–∫", callback_data='run_full_benchmark')],
        [InlineKeyboardButton("üìä –ü–æ–∫–∞–∑–∞—Ç—å –ª–∏–¥–µ—Ä–±–æ—Ä–¥", callback_data='show_leaderboard')],
        [InlineKeyboardButton("üìã –°–ø–∏—Å–æ–∫ —Ç–µ—Å—Ç–æ–≤—ã—Ö –∑–∞–¥–∞–Ω–∏–π", callback_data='show_benchmark_tasks')],
        [InlineKeyboardButton("üß™ –ü—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å –æ–¥–Ω—É –º–æ–¥–µ–ª—å", callback_data='test_single_model')],
        [InlineKeyboardButton("üîô –ù–∞–∑–∞–¥", callback_data='admin_panel')]
    ]
    
    await query.edit_message_text(
        text or "üèÜ *–ú–µ–Ω—é –±–µ–Ω—á–º–∞—Ä–∫–∏–Ω–≥–∞*\n\n–ó–¥–µ—Å—å –≤—ã –º–æ–∂–µ—Ç–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å –∏ —Å—Ä–∞–≤–Ω–∏–≤–∞—Ç—å –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å —Ä–∞–∑–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π.",
        reply_markup=InlineKeyboardMarkup(keyboard),
        parse_mode='Markdown'
    )

@handle_errors
async def run_full_benchmark_handler(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –∑–∞–ø—É—Å–∫–∞ –ø–æ–ª–Ω–æ–≥–æ –±–µ–Ω—á–º–∞—Ä–∫–∞"""
    query = update.callback_query
    user_id = query.from_user.id
    
    await query.answer()
    initialize_user(user_id)
    
    if user_data[user_id]['benchmark_status'] == BenchmarkStatus.RUNNING.value:
        await query.answer("‚ö†Ô∏è –ë–µ–Ω—á–º–∞—Ä–∫ —É–∂–µ –∑–∞–ø—É—â–µ–Ω", show_alert=True)
        return
    
    # –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π
    models = await get_available_models(refresh=True)
    if not models:
        await query.edit_message_text(
            "‚ùå –ù–µ—Ç –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è.",
            reply_markup=InlineKeyboardMarkup([
                [InlineKeyboardButton("üîô –ù–∞–∑–∞–¥", callback_data='benchmark_menu')]
            ])
        )
        return
    
    await query.edit_message_text(
        f"üöÄ *–ó–∞–ø—É—Å–∫ –ø–æ–ª–Ω–æ–≥–æ –±–µ–Ω—á–º–∞—Ä–∫–∞*\n\n"
        f"–ë—É–¥—É—Ç –ø—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω—ã {len(models)} –º–æ–¥–µ–ª–µ–π:\n"
        + "\n".join(f"‚Ä¢ {model}" for model in models[:10]) +
        (f"\n... –∏ –µ—â–µ {len(models) - 10} –º–æ–¥–µ–ª–µ–π" if len(models) > 10 else "") +
        f"\n\n–í—Å–µ–≥–æ –∑–∞–¥–∞–Ω–∏–π: {len(CONFIG['BENCHMARK_TASKS'])}"
        f"\n–û–∂–∏–¥–∞–µ–º–æ–µ –≤—Ä–µ–º—è: ~{len(models) * len(CONFIG['BENCHMARK_TASKS']) * 15} —Å–µ–∫—É–Ω–¥"
        f"\n\n*–ù–∞—á–∏–Ω–∞—é —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ...*",
        parse_mode='Markdown'
    )
    
    # –ó–∞–ø—É—Å–∫–∞–µ–º –±–µ–Ω—á–º–∞—Ä–∫ –≤ —Ñ–æ–Ω–µ
    asyncio.create_task(run_benchmark_and_report(models, user_id, query))

async def run_benchmark_and_report(models: List[str], user_id: int, query):
    """–ó–∞–ø—É—Å–∫ –±–µ–Ω—á–º–∞—Ä–∫–∞ –∏ –æ—Ç–ø—Ä–∞–≤–∫–∞ –æ—Ç—á–µ—Ç–æ–≤"""
    try:
        results = await run_full_benchmark(models, user_id)
        
        if results:
            # –§–æ—Ä–º–∏—Ä—É–µ–º –æ—Ç—á–µ—Ç
            report = format_benchmark_results(results)
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–µ—Ç–∞–ª—å–Ω—ã–π –æ—Ç—á–µ—Ç –≤ —Ñ–∞–π–ª
            timestamp = int(time.time())
            report_filename = f'benchmarks/report_{user_id}_{timestamp}.txt'
            with open(report_filename, 'w', encoding='utf-8') as f:
                f.write(report)
            
            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Å–≤–æ–¥–Ω—ã–π –æ—Ç—á–µ—Ç
            summary_lines = report.split('\n')[:50]  # –ü–µ—Ä–≤—ã–µ 50 —Å—Ç—Ä–æ–∫
            summary = '\n'.join(summary_lines)
            
            if len(report) > 4000:
                parts = split_long_message(report, 4000)
                for i, part in enumerate(parts):
                    if i == 0:
                        await query.edit_message_text(
                            f"üìä *–û—Ç—á–µ—Ç –æ –±–µ–Ω—á–º–∞—Ä–∫–µ* (—á–∞—Å—Ç—å {i+1}/{len(parts)})\n\n{part}",
                            parse_mode='Markdown'
                        )
                    else:
                        await query.effective_chat.send_message(
                            f"üìä *–û—Ç—á–µ—Ç –æ –±–µ–Ω—á–º–∞—Ä–∫–µ* (—á–∞—Å—Ç—å {i+1}/{len(parts)})\n\n{part}",
                            parse_mode='Markdown'
                        )
            else:
                await query.edit_message_text(
                    f"üìä *–û—Ç—á–µ—Ç –æ –±–µ–Ω—á–º–∞—Ä–∫–µ*\n\n{report}",
                    parse_mode='Markdown',
                    reply_markup=InlineKeyboardMarkup([
                        [InlineKeyboardButton("üèÜ –õ–∏–¥–µ—Ä–±–æ—Ä–¥", callback_data='show_leaderboard')],
                        [InlineKeyboardButton("üîô –í –º–µ–Ω—é", callback_data='benchmark_menu')]
                    ])
                )
        else:
            await query.edit_message_text(
                "‚ùå –ë–µ–Ω—á–º–∞—Ä–∫ –∑–∞–≤–µ—Ä—à–∏–ª—Å—è –±–µ–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤. –í–æ–∑–º–æ–∂–Ω–æ, –≤—Å–µ –º–æ–¥–µ–ª–∏ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã.",
                reply_markup=InlineKeyboardMarkup([
                    [InlineKeyboardButton("üîô –í –º–µ–Ω—é", callback_data='benchmark_menu')]
                ])
            )
            
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–∏ –±–µ–Ω—á–º–∞—Ä–∫–∞: {e}", exc_info=True)
        await query.edit_message_text(
            f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–∏ –±–µ–Ω—á–º–∞—Ä–∫–∞: {str(e)}",
            reply_markup=InlineKeyboardMarkup([
                [InlineKeyboardButton("üîô –í –º–µ–Ω—é", callback_data='benchmark_menu')]
            ])
        )

@handle_errors
async def show_leaderboard_handler(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è –ª–∏–¥–µ—Ä–±–æ—Ä–¥–∞"""
    query = update.callback_query
    user_id = query.from_user.id
    
    await query.answer()
    initialize_user(user_id)
    
    leaderboard = await get_model_leaderboard()
    
    await query.edit_message_text(
        leaderboard,
        parse_mode='Markdown',
        reply_markup=InlineKeyboardMarkup([
            [InlineKeyboardButton("üîÑ –û–±–Ω–æ–≤–∏—Ç—å", callback_data='show_leaderboard')],
            [InlineKeyboardButton("üîô –í –º–µ–Ω—é", callback_data='benchmark_menu')]
        ])
    )

@handle_errors
async def show_benchmark_tasks_handler(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è —Ç–µ—Å—Ç–æ–≤—ã—Ö –∑–∞–¥–∞–Ω–∏–π"""
    query = update.callback_query
    user_id = query.from_user.id
    
    await query.answer()
    initialize_user(user_id)
    
    tasks_text = "üìã *–¢–µ—Å—Ç–æ–≤—ã–µ –∑–∞–¥–∞–Ω–∏—è –±–µ–Ω—á–º–∞—Ä–∫–∞*\n\n"
    for i, task in enumerate(CONFIG['BENCHMARK_TASKS']):
        tasks_text += f"*{i+1}. {task['name']}*\n"
        tasks_text += f"   –ó–∞–ø—Ä–æ—Å: `{task['prompt']}`\n"
        tasks_text += f"   –û–∂–∏–¥–∞–µ–º—ã–π –æ—Ç–≤–µ—Ç: {task['expected_answer']}\n\n"
    
    await query.edit_message_text(
        tasks_text,
        parse_mode='Markdown',
        reply_markup=InlineKeyboardMarkup([
            [InlineKeyboardButton("üîô –í –º–µ–Ω—é", callback_data='benchmark_menu')]
        ])
    )

@handle_errors
async def test_single_model_handler(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –æ–¥–Ω–æ–π –º–æ–¥–µ–ª–∏"""
    query = update.callback_query
    user_id = query.from_user.id
    
    await query.answer()
    initialize_user(user_id)
    
    models = await get_available_models()
    if not models:
        await query.edit_message_text(
            "‚ùå –ù–µ—Ç –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π.",
            reply_markup=InlineKeyboardMarkup([
                [InlineKeyboardButton("üîô –í –º–µ–Ω—é", callback_data='benchmark_menu')]
            ])
        )
        return
    
    # –°–æ–∑–¥–∞–µ–º –∫–Ω–æ–ø–∫–∏ –¥–ª—è –≤—ã–±–æ—Ä–∞ –º–æ–¥–µ–ª–∏
    buttons = []
    for model in models[:20]:  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º 20 –º–æ–¥–µ–ª—è–º–∏
        model_info = model_info_cache.get(model, {})
        score = model_info.get('benchmark_score', 0)
        score_text = f" ({score:.2f})" if score > 0 else ""
        buttons.append(
            InlineKeyboardButton(f"{model}{score_text}", callback_data=f"benchmark_model_{model}")
        )
    
    keyboard = [buttons[i:i + 2] for i in range(0, len(buttons), 2)]
    keyboard.append([InlineKeyboardButton("üîô –í –º–µ–Ω—é", callback_data='benchmark_menu')])
    
    await query.edit_message_text(
        "üß™ *–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –æ–¥–Ω–æ–π –º–æ–¥–µ–ª–∏*\n\n–í—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª—å –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è:",
        reply_markup=InlineKeyboardMarkup(keyboard),
        parse_mode='Markdown'
    )

@handle_errors
async def benchmark_model_handler(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π –º–æ–¥–µ–ª–∏"""
    query = update.callback_query
    user_id = query.from_user.id
    
    await query.answer()
    initialize_user(user_id)
    
    model_name = query.data.replace('benchmark_model_', '')
    
    await query.edit_message_text(
        f"üß™ *–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏: {model_name}*\n\n–ù–∞—á–∏–Ω–∞—é —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ...",
        parse_mode='Markdown'
    )
    
    # –ó–∞–ø—É—Å–∫–∞–µ–º —Ç–µ—Å—Ç –¥–ª—è –æ–¥–Ω–æ–π –º–æ–¥–µ–ª–∏
    tasks = [BenchmarkTask(**task) for task in CONFIG['BENCHMARK_TASKS']]
    results = []
    
    for task in tasks:
        result = await run_benchmark_task(model_name, task)
        if result:
            results.append(result)
    
    if results:
        avg_score = statistics.mean([r.score for r in results])
        avg_time = statistics.mean([r.response_time for r in results])
        avg_tps = statistics.mean([r.tokens_per_second for r in results])
        
        report = f"üìä *–†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è: {model_name}*\n\n"
        report += f"–°—Ä–µ–¥–Ω—è—è –æ—Ü–µ–Ω–∫–∞: *{avg_score:.2f}/1.0*\n"
        report += f"–°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è –æ—Ç–≤–µ—Ç–∞: *{avg_time:.2f}—Å*\n"
        report += f"–°–∫–æ—Ä–æ—Å—Ç—å –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: *{avg_tps:.1f} —Ç–æ–∫–µ–Ω–æ–≤/—Å–µ–∫*\n\n"
        report += "*–î–µ—Ç–∞–ª–∏ –ø–æ –∑–∞–¥–∞—á–∞–º:*\n"
        
        for result in results:
            status = "‚úÖ" if result.score >= 0.7 else "‚ö†Ô∏è" if result.score >= 0.3 else "‚ùå"
            report += f"{status} {result.task_name}: {result.score:.1f} ({result.response_time:.1f}—Å)\n"
            report += f"   –û—Ü–µ–Ω–∫–∞: {result.evaluation}\n"
            report += f"   –û—Ç–≤–µ—Ç: _{result.raw_response}_\n\n"
        
        await query.edit_message_text(
            report,
            parse_mode='Markdown',
            reply_markup=InlineKeyboardMarkup([
                [InlineKeyboardButton("üèÜ –õ–∏–¥–µ—Ä–±–æ—Ä–¥", callback_data='show_leaderboard')],
                [InlineKeyboardButton("üîô –í –º–µ–Ω—é", callback_data='benchmark_menu')]
            ])
        )
    else:
        await query.edit_message_text(
            f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å –º–æ–¥–µ–ª—å {model_name}",
            reply_markup=InlineKeyboardMarkup([
                [InlineKeyboardButton("üîô –í –º–µ–Ω—é", callback_data='benchmark_menu')]
            ])
        )

async def post_init(application):
    """–ü–æ—Å—Ç-–∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è"""
    logger.info("–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –±–æ—Ç–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞")
    if application.job_queue:
        application.job_queue.run_repeating(
            backup_task,
            interval=CONFIG['BACKUP_INTERVAL'],
            first=10
        )

async def shutdown():
    """–ö–æ—Ä—Ä–µ–∫—Ç–Ω–æ–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏–µ —Ä–∞–±–æ—Ç—ã"""
    logger.info("–ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ —Ä–∞–±–æ—Ç—ã...")
    shutdown_event.set()
    
    # –û—Ç–º–µ–Ω—è–µ–º –≤—Å–µ –∞–∫—Ç–∏–≤–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã
    for task in active_requests.values():
        task.cancel()
        try:
            await task
        except asyncio.CancelledError:
            pass
    
    # –°–æ–∑–¥–∞–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–π –±—ç–∫–∞–ø
    await backup_data()
    logger.info("–§–∏–Ω–∞–ª—å–Ω—ã–π –±—ç–∫–∞–ø —Å–æ–∑–¥–∞–Ω")
    
    # –ó–∞–∫—Ä—ã–≤–∞–µ–º –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ
    application = ApplicationBuilder().build()  # –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä
    await application.stop()
    await application.shutdown()


def handle_signal(signum, frame):
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ —Å–∏–≥–Ω–∞–ª–æ–≤ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è"""
    logger.info(f"–ü–æ–ª—É—á–µ–Ω —Å–∏–≥–Ω–∞–ª {signum}, –∑–∞–≤–µ—Ä—à–∞–µ–º —Ä–∞–±–æ—Ç—É...")
    asyncio.create_task(shutdown())

async def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    setup_logging()
    setup_directories()
    
    try:
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –±—ç–∫–∞–ø—ã
        await load_backup()
        
        application = ApplicationBuilder() \
            .token(CONFIG['TOKEN']) \
            .post_init(post_init) \
            .build()
        
        # –û–±—Ä–∞–±–æ—Ç—á–∏–∫–∏ –∫–æ–º–∞–Ω–¥
        application.add_handler(CommandHandler('start', start))
        application.add_handler(CommandHandler('help', start))
        application.add_handler(CommandHandler('model', lambda u, c: show_models_menu(u.callback_query)))
        application.add_handler(CommandHandler('stats', lambda u, c: show_stats_menu(u.callback_query)))
        application.add_handler(CommandHandler('settings', lambda u, c: show_settings_menu(u.callback_query)))
        application.add_handler(CommandHandler('benchmark', benchmark_command))
        application.add_handler(CommandHandler('leaderboard', leaderboard_command))
        
        # –û–±—Ä–∞–±–æ—Ç—á–∏–∫–∏ —Å–æ–æ–±—â–µ–Ω–∏–π
        application.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_message))
        application.add_handler(CallbackQueryHandler(button_handler))
        
        # –ó–∞–ø—É—Å–∫ –±–æ—Ç–∞
        logger.info("–ë–æ—Ç –∑–∞–ø—É—Å–∫–∞–µ—Ç—Å—è...")
        await application.initialize()
        await application.start()
        await application.updater.start_polling()
        
        # –û–∂–∏–¥–∞–µ–º –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è
        while True:
            await asyncio.sleep(1)
            
    except asyncio.CancelledError:
        pass
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—É—Å–∫–µ –±–æ—Ç–∞: {e}", exc_info=True)
    finally:
        await shutdown()
        logger.info("–ë–æ—Ç –∑–∞–≤–µ—Ä—à–∏–ª —Ä–∞–±–æ—Ç—É")

if __name__ == '__main__':
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        pass
